# Airflow Patterns â€“ PoC

This is a quick Proof of Concept to demonstrate three simple and powerful patterns in Apache Airflow:

- ðŸ§© **Task Groups**: For visual organization and better readability
- âš™ï¸ **Dynamic DAGs**: For scalable, DRY pipeline generation
- â±ï¸ **Sensors with Timeout + Fallback**: For robust and resilient workflows

## ðŸ”§ Requirements

- Python 3.7 or higher
- pip
- Virtualenv (optional, but recommended)

## ðŸš€ Getting Started

### 1. Clone this repo

```bash
git clone https://github.com/gfnogueira/airflow-patterns-poc.git
cd airflow-patterns-poc
```

### 2. Create a virtual environment (optional)

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Airflow

```bash
AIRFLOW_VERSION=2.8.1
PYTHON_VERSION="$(python --version | cut -d ' ' -f 2 | cut -d '.' -f 1-2)"
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"

pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
```

### 4. Initialize Airflow

```bash
export AIRFLOW_HOME=~/airflow
airflow db init
```

### 5. Create admin user

```bash
airflow users create \
  --username admin \
  --firstname Admin \
  --lastname Nogueira \
  --role Admin \
  --email admin@example.com \
  --password admin
```

### 6. Start Airflow

In two terminals:

```bash
# Terminal 1
airflow webserver --port 8080

# Terminal 2
airflow scheduler
```

Access the UI at [http://localhost:8080](http://localhost:8080)

---

### Optional to run on terminal;

You have two options to run the webserver and scheduler without blocking your terminal:  

âœ… Option 1: Run in background with &

```bash
# Start the webserver in the background
airflow webserver --port 8080 &

# Start the scheduler in the background
airflow scheduler &
```

âœ… Option 2: Run with nohup to keep it running after logout  

```bash
# Start the webserver and save logs
nohup airflow webserver --port 8080 > webserver.log 2>&1 &

# Start the scheduler and save logs
nohup airflow scheduler > scheduler.log 2>&1 &
```

This will keep the processes running even if you close the terminal.  
You can view logs using:  
`tail -f webserver.log or tail -f scheduler.log`

---

### 7. DAGs

All example DAGs are located in the `dags/` folder:
- `task_group.py`
- `dynamic_dags.py`
- `sensor_timeout_fallback.py`

Just place them in `$AIRFLOW_HOME/dags/` or set a custom path via `airflow.cfg`.

---

## ðŸ§ª Demo Overview

Each DAG demonstrates a specific pattern covered in the presentation:

| DAG Name               | Pattern                     |
|------------------------|-----------------------------|
| `task_group`           | Task Group usage            |
| `dag_pipeline1`, `2`   | Dynamic DAG generation      |
| `sensor_timeout_pattern` | Timeout & fallback with sensor |

---